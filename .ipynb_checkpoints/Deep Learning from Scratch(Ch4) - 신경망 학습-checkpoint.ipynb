{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장. 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/WegraLee/deep-learning-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드의 내용은 Deep Learning from Scratch를 참고했음을 밝힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 제곱 오차(p112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/2imx4Ia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] # 소프트맥스 함수의 출력(확률)\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 레이블(원-핫 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답은 '2'\n",
    "t = [0,0,1,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예1 : '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예2 : '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차(p113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/9JUwq7G.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta)) # np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 더 이상 계산을 진행할 수 없게 되기 때문에 아주 작은 값을 더해서 절대 0이 되지 않도록, 즉 마이너스 무한대가 발생하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습(p115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/eXuPI0m.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34312, 51526, 51296, 49627, 22242, 31382, 31184, 28054, 31480,\n",
       "        7738])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.choice()로는 지정한 범위의 수 중에서 무작위로 원하는 개수만 꺼낼 수 있습니다.\n",
    "\n",
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (배치용) 교차 엔트로피 오차 구현하기(p118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log*(y+1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블이 원-핫 인코딩이 아니라 '2'나 '7' 등의 숫자 레이블로 주어졌을 때\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분(p121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50\n",
    "    return (f(x+h) - f(x))/h\n",
    "\n",
    "\n",
    "# 개선 1\n",
    "# h에 가급적 작은 값을 대입하고 싶었기에(가능하다면 h를 0으로 무한히 가깝게 하고 싶으니) 10e-50이라는 작은 값을 이용했습니다.\n",
    "# 이 값은 0.00...1 형태에서 0이 50개라는 의미죠.\n",
    "# 그러나 이 방식은 반올림 오차(rounding error) 문제를 일으킵니다.\n",
    "# 반올림 오차는 작은 값(가령 소수점 8자리 이하)이 생략되어 최종 계산 결과에 오차가 생기게 합니다.\n",
    "# 이 미세한 값 h로 10**-4을 이용해봅시다. 10**-4 정도의 값을 사용하면 좋은 결과를 얻는다고 알려져 있습니다.\n",
    "\n",
    "# 개선 2\n",
    "# 함수 f의 차분(임의 두 점에서의 함수 값들의 차이)과 관련한 것입니다.\n",
    "# x+h와 x 사이의 함수 f의 차분을 계산하고 있지만, 애당초 이 계산에는 오차가 있다는 사실에 주의해야 합니다.\n",
    "# '진정한 미분'은 x 위치의 함수의 기울기(이를 접선이라 함)에 해당하지만, 이번 구현에서의 미분은 (x+h)와 x 사이의 기울기에 해당합니다.\n",
    "# 그래서 진정한 미분(진정한 접선)과 이번 구현의 값은 엄밀히는 일치하지 않습니다.\n",
    "# 이 차이는 h를 무한히 0으로 좁히는 것이 불가능해 생기는 한계입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반올림 오차\n",
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 진정한 미분(진정한 접선)과 수치 미분(근사로 구한 접선)의 값은 다르다.<br>\n",
    "![image.png](https://i.imgur.com/z4hzRS4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림과 같이 수치 미분에는 오차가 포함됩니다. 이 오차를 줄이기 위해 (x+h)와 (x-h)일 때의 함수 f의 차분을 계산하는 방법을 쓰기도 합니다. 이 차분은 x를 중심으로 그 전후의 차분을 계산한다는 의미에서 중심 차분 혹은 중앙 차분이라 합니다(한편, (x+h)와 x의 차분은 전방 차분이라 합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상의 두 개선점을 적용해 수치 미분을 다시 구현\n",
    "\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 미분의 예\n",
    "\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이 함수를 그려봅시다.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) # 0에서 20까지 0.1 간격의 배열 x를 만든다.\n",
    "y = function_1(x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = 5일때와 10일 떄 이 함수의 미분을 계산해봅시다.\n",
    "\n",
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분(p125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "# 또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4일 때, x0에 대한 편미분을 구하라\n",
    "\n",
    "def function_tmp1(x0):\n",
    "    return x0**2 + 4.0**2.0\n",
    "    # 또는 return np.sum(x**2)\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4일 때, x1에 대한 편미분을 구하라\n",
    "\n",
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기(p127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # x와 형상이 같고 그 원소가 모두 0인 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1- fxh2)/(2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/IZjpn81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림에서 기울기는 가장 낮은 장소를 가리킵니다만, 실제는 반드시 그렇다고는 할 수 없습니다. 사실 기울기는 각 지점에서 낮아지는 방향을 가리킵니다. 더 정확히 말하자면 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사법(경사 하강법)(p129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인수 f는 최적화하려는 함수, init_x는 초깃값, lr은 learning rate를 의미하는 학습률, step_num은 경사법에 따른 반복 횟수를 뜻합니다.\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10.0\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률과 같은 매개변수를 하이퍼파라미터(hyper parameter, 초매개변수)라고 합니다. 이는 가중치와 편향 같은 신경망의 매개변수와는 성질이 다른 매개변수입니다. 신경망의 가중치 매개변수는 훈련 데이터와 학습 알고리즘에 의해서 '자동'으로 획득되는 매개변수인 반면, 학습률 같은 하이퍼파라미터는 사람이 직접 설정해야 하는 매개변수인 것이죠. 일반적으로는 이 하이퍼파라미터들은 여러 후보 값 중에서 시험을 통해 가장 잘 학습하는 값을 찾는 과정을 거쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.70474501  0.91104719  1.18766659]\n",
      " [-0.13536328 -0.19119192  0.76806372]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W) # 가중치 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.14467396  0.37455558  1.4038573 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최댓값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36148017547156813"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0,0,1]) # 정답 레이블\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03268505  0.14932834 -0.18201339]\n",
      " [ 0.04902758  0.2239925  -0.27302008]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬에서는 간단한 함수라면 람다(lambda) 기법을 쓰면 더 편합니다.\n",
    "# 가령 lambda를 쓰면 다음과 같이 구현할 수 있습니다.\n",
    "\n",
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 알고리즘 구현하기(p136)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전제\n",
    "* 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라 합니다. 신경망 학습은 다음과 같이 4단계로 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1단계 - 미니배치\n",
    "* 훈련 데이터 중 일부를 무작위로 가져옵니다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실함수 값을 줄이는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2단계 - 기울기 산출\n",
    "* 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3단계 - 매개변수 갱신\n",
    "* 가중치 매개변수를 기울기 방향으로 아주 조금 갱신합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4단계 - 반복\n",
    "* 1~3단계를 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 클래스 구현하기(p137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    # 초기화를 수행한다.\n",
    "    # 인수는 순서대로 입력층의 뉴런 수, 은닉층의 뉴런 수, 출력층의 뉴런 수\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {} # 신경망의 매개변수를 보관하는 딕셔너리 변수(인스턴스 변수)\n",
    "        self.params['W1'] = weight_init_std*\\\n",
    "                            np.random.randn(input_size, hidden_size) # 1번째 층의 가중치\n",
    "        self.params['b1'] = np.zeros(hidden_size) # 1번째 층의 편향\n",
    "        self.params['W2'] = weight_init_std*\\\n",
    "                            np.random.randn(hidden_size, output_size) # 2번째 층의 가중치\n",
    "        self.params['b2'] = np.zeros(output_size) # 2번째 층의 편향\n",
    "        \n",
    "    \n",
    "    # 예측(추론)을 수행한다.\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    # 손실 함수의 값을 구한다.\n",
    "    # 인수 x는 이미지 데이터, t는 정답 레이블\n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    \n",
    "    # 정확도를 구한다.\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    # 가중치 매개변수의 기울기를 구한다.\n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {} # 기울기 보관하는 딕셔너리 변수(numerical_gradient() 메서드의 반환 값)\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1']) # 1번째 층의 가중치의 기울기\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1']) # 1번째 층의 편향의 기울기\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2']) # 2번째 층의 가중치의 기울기\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2']) # 2번째 층의 편향의 기울기\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4ab602f83618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 더미 정답 레이블(100장 분량)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 기울기 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-592e597ea0df>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# 기울기 보관하는 딕셔너리 변수(numerical_gradient() 메서드의 반환 값)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1번째 층의 가중치의 기울기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1번째 층의 편향의 기울기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 2번째 층의 가중치의 기울기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\common\\gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-592e597ea0df>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# 기울기 보관하는 딕셔너리 변수(numerical_gradient() 메서드의 반환 값)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-592e597ea0df>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-592e597ea0df>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
    "t = np.random.rand(100, 10) # 더미 정답 레이블(100장 분량)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
    "\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습 구현하기(p141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-19de4d6d8123>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# 기울기 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;31m# grad = network.gradient(x_batch, t_batch) # 성능 개선판!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\common\\gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mfxh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x+h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선판!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시험 데이터로 평가하기(p143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-8fa345f2fc47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# 기울기 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# grad = network.gradient(x_batch, t_batch) # 성능 개선판!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\common\\gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-Scratch\\ch04\\two_layer_net.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선판!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i%iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('train acc, test acc | '\n",
    "             + str(train_acc) + ', ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리(p146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용한다.\n",
    "* 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다.\n",
    "* 신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다.\n",
    "* 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다.\n",
    "* 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 한다.\n",
    "* 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.\n",
    "* 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 (다소 복잡한) 오차역전파법은 기울기를 고속으로 구할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
